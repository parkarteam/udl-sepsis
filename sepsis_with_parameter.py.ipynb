{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 81.0, 37.17, 57, 99.0, 114.0, 17.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 79.0, 0, 57, 99.0, 111.0, 14.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 69.0, 0, 57, 98.0, 147.0, 13.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 65.0, 0, 57, 98.0, 117.0, 19.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 64.0, 0, 57, 98.0, 112.0, 12.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 61.0, 0, 57, 98.0, 108.0, 11.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 57.0, 36.11, 57, 99.0, 101.0, 11.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 59.0, 0, 57, 98.0, 103.0, 11.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 57.0, 0, 57, 99.0, 103.0, 11.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 80.0, 0, 57, 100.0, 126.0, 13.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 81.0, 0, 57, 99.0, 119.0, 13.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 91.0, 36.56, 57, 100.0, 130.0, 23.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 98.0, 0, 57, 100.0, 118.0, 18.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 84.0, 0, 57, 100.0, 0, 15.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 81.0, 0, 57, 98.0, 120.0, 16.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 67.0, 0, 57, 98.0, 109.0, 12.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 62.0, 36.33, 57, 99.0, 108.0, 13.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 70.0, 0, 57, 99.0, 87.0, 14.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 68.0, 0, 57, 98.0, 112.0, 14.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 83.0, 0, 57, 100.0, 108.0, 22.0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 0, 0, 57, 0, 0, 0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "[[1, 0, 0, 57, 0, 0, 0, 0, 0]]\n",
      "Sepsis detected 0 \n",
      "Script Completed\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Oct 12 15:38:30 2020\n",
    "\n",
    "@author: Prakash.Gore\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import mysql.connector\n",
    "from minio import Minio\n",
    "from itertools import groupby\n",
    "import itertools\n",
    "import csv\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from config import *\n",
    "\n",
    "file=open('udl_script.log', 'w')\n",
    "#endpoint = \"http://demo-classifier-lr-predictor.odh-sepsis.svc.cluster.local:8000/api/v1.0/predictions\"\n",
    "current_timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "def date_diff_in_seconds(dt2, dt1):\n",
    "    timedelta = dt2 - dt1\n",
    "    return timedelta.seconds/60\n",
    "\n",
    "def validate_string(val):\n",
    "   if val != None:\n",
    "        if type(val) is int:\n",
    "            return str(val).encode('utf-8')\n",
    "        else:\n",
    "            return val\n",
    "\n",
    "def calculateAge(birthDate): \n",
    "\ttoday = date.today() \n",
    "\tage = today.year - birthDate.year\n",
    "\treturn age \n",
    "\n",
    "def returnSex(Gender):\n",
    "    if Gender == 'M':\n",
    "        return \"Male\"\n",
    "    elif Gender == 'F':\n",
    "        return \"Female\"\n",
    "    else :\n",
    "        return \"NA\"\n",
    "def returnGender(Gender):\n",
    "    if Gender == 1:\n",
    "        return \"Male\"\n",
    "    elif Gender == 0:\n",
    "        return \"Female\"\n",
    "    else :\n",
    "        return \"NA\"\n",
    "    \n",
    "def returnSexInt(Gender):\n",
    "    if Gender == 'M':\n",
    "        return 1\n",
    "    elif Gender == 'F':\n",
    "        return 0\n",
    "    else :\n",
    "        return \"NA\"\n",
    "    \n",
    "mydb = mysql.connector.connect(\n",
    "    host=db_creds['host'],\n",
    "    user=db_creds['user'],\n",
    "    password=db_creds['password'],\n",
    "    database=db_creds['database'],\n",
    "    auth_plugin=db_creds['auth_plugin']\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "client = Minio(minio_creds['host'], access_key=minio_creds['access_key'], secret_key=minio_creds['secret_key'], secure=False)\n",
    "objects_labs = client.list_objects(minio_creds['bucketName'], prefix=minio_prefix_labs, recursive=True)\n",
    "objects_demographic = client.list_objects(minio_creds['bucketName'], prefix=minio_prefix_demographic, recursive=True)\n",
    "objects_vitalsigns = client.list_objects(minio_creds['bucketName'], prefix=minio_prefix_vitalsigns, recursive=True)\n",
    "objects_json = client.list_objects(minio_creds['bucketName'], prefix=minio_prefix_json, recursive=True)\n",
    "\n",
    "\n",
    "for (obj_json) in (objects_json):\n",
    "    json_name = os.path.basename(obj_json.object_name)\n",
    "    json_name1 = os.path.splitext(json_name)[0]\n",
    "    splitResult = json_name1.split( \"_\" )\n",
    "    json_pid_filename = splitResult[0]\n",
    "    json_filename = splitResult[1]\n",
    "    json_data = client.get_object(minio_creds['bucketName'], obj_json.object_name)\n",
    "    with open(json_name, 'wb') as file_data:\n",
    "        for d_json in json_data.stream(32*1024):\n",
    "            file_data.write(d_json)\n",
    "\n",
    "\n",
    "for (obj_demographic) in (objects_demographic):\n",
    "    demographic_name = os.path.basename(obj_demographic.object_name)\n",
    "    demographic_data = client.get_object(minio_creds['bucketName'], obj_demographic.object_name)\n",
    "    with open(demographic_name, 'wb') as file_data:\n",
    "        for d_demographic in demographic_data.stream(32*1024):\n",
    "            file_data.write(d_demographic)\n",
    "            \n",
    "    \n",
    "\n",
    "for (obj_vitalsigns, obj_labs) in itertools.zip_longest( objects_vitalsigns, objects_labs):\n",
    "    vitalsigns_file_date = obj_vitalsigns.last_modified\n",
    "    vitalsigns_file_date = vitalsigns_file_date.replace(tzinfo=None)\n",
    "    current_time = datetime.now()\n",
    "    diff = date_diff_in_seconds(current_time, vitalsigns_file_date)\n",
    "    vitalsign_name = os.path.basename(obj_vitalsigns.object_name)\n",
    "    vitalsign_name1 = os.path.splitext(vitalsign_name)[0]\n",
    "    splitResult = vitalsign_name1.split( \"_\" )\n",
    "    vitalsign_pid_filename = splitResult[0]\n",
    "    vitalsign_filename = splitResult[1]\n",
    "    vitalsign_json_name = vitalsign_pid_filename + longitudnaljsonfile\n",
    "    \n",
    "    labs_file_date = obj_labs.last_modified\n",
    "    labs_file_date = labs_file_date.replace(tzinfo=None)\n",
    "    current_time = datetime.now()\n",
    "    labs_name = os.path.basename(obj_labs.object_name)\n",
    "    labs_name1 = os.path.splitext(labs_name)[0]\n",
    "    splitResult = labs_name1.split( \"_\" )\n",
    "    labs_pid_filename = splitResult[0]\n",
    "    labs_filename = splitResult[1]\n",
    "    labs_json_name = labs_pid_filename + longitudnaljsonfile\n",
    "    diff1 = date_diff_in_seconds(current_time, labs_file_date)\n",
    "\n",
    "    vitalsign_data = client.get_object(minio_creds['bucketName'], obj_vitalsigns.object_name)\n",
    "\n",
    "    with open(vitalsign_pid_filename + vitalsignscsv, 'wb') as file_data:\n",
    "        for d in vitalsign_data.stream(32*1024):\n",
    "            file_data.write(d)\n",
    "\n",
    "    labs_data = client.get_object(minio_creds['bucketName'], obj_labs.object_name)\n",
    "    with open(labs_pid_filename + labscsv, 'wb') as file_data:\n",
    "        for d in labs_data.stream(32*1024):\n",
    "            file_data.write(d)\n",
    "            \n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    if os.path.isfile(vitalsign_json_name):\n",
    "        with open(vitalsign_json_name, 'rb') as json_data:\n",
    "            output = json.load(json_data)\n",
    "    else:\n",
    "        output = {'Demographic': [],'Vital_Signs':[],'labs':[]}\n",
    "        with open(vitalsign_pid_filename + demographiccsv, 'r') as csv_demographic:\n",
    "            r = csv.DictReader(csv_demographic)\n",
    "            data_demographic = [dict(d) for d in r]\n",
    "            \n",
    "        def keyfunc(x):\n",
    "            return x['Patient_id']\n",
    "        \n",
    "        for k, g in groupby(data_demographic, lambda r: (r['Patient_id'], r['DOB'],r['Gender'],r['Unit1'],r['Unit2'],r['HospAdmTime'])):\n",
    "            output['Demographic'].append({\n",
    "                \"Patient_id\": k[0],\n",
    "                \"Age\" :str(k[1]),\n",
    "                \"Gender\":str(k[2]),\n",
    "                \"Unit1\":str(k[3]),\n",
    "                \"Unit2\":str(k[4]),\n",
    "                \"HospAdmTime\":str(k[5])\n",
    "                })\n",
    "            \n",
    "        with open(vitalsign_pid_filename + longitudnaljsonfile, 'w') as outfile:\n",
    "            outfile.write(json.dumps(output, indent=4))\n",
    "             \n",
    "\n",
    "    Demographic = output[\"Demographic\"]\n",
    "    Demographic = dict(Demographic[0])\n",
    "    Age = str(validate_string(Demographic['Age']))\n",
    "    Gender = str(validate_string(Demographic['Gender']))\n",
    "    Unit1 = str(validate_string(Demographic['Unit1']))\n",
    "    Unit2 = str(validate_string(Demographic['Unit2']))\n",
    "    HospAdmTime = str(validate_string(Demographic['HospAdmTime']))\n",
    "   # print(Demographic)\n",
    "    Age = datetime.strptime(Age, '%Y-%m-%d')\n",
    "\n",
    "  \n",
    "            \n",
    "    if (vitalsign_pid_filename==labs_pid_filename and  diff < frequency and diff1 < frequency):\n",
    "        with open(vitalsign_json_name, 'rb') as json_data:\n",
    "            output = json.load(json_data)\n",
    "        with open(vitalsign_pid_filename + vitalsignscsv, 'r') as csv_vital_signs:\n",
    "            r = csv.DictReader(csv_vital_signs)\n",
    "            data_vital_signs = [dict(d) for d in r]\n",
    "    \n",
    "        for k, g in groupby(data_vital_signs, lambda r: (r['Time'], r['HR'],r['O2Sat'],r['Temp'],r['SBP'],r['MAP'],r['DBP'],r['Resp'],r['EtCO2'],r['ICULOS'])):\n",
    "            output['Vital_Signs'].append({  \n",
    "                    \"Time\": k[0],\n",
    "                    \"HR\" :str(k[1]),\n",
    "                    \"O2Sat\" :str(k[2]),\n",
    "                    \"Temp\" :str(k[3]),\n",
    "                    \"SBP\" :str(k[4]),\n",
    "                    \"MAP\" :str(k[5]),\n",
    "                    \"DBP\" :str(k[6]),\n",
    "                    \"Resp\" :str(k[7]),\n",
    "                    \"EtCO2\":str(k[8]),\n",
    "                    \"ICULOS\":str(k[9])\n",
    "            })\n",
    "            Vital_Signs_Array = [returnSexInt(Gender),float(k[1]),float(k[3]),calculateAge(Age),float(k[2]),float(k[4]),float(k[7]),float(k[9]),float(HospAdmTime)]\n",
    "            Vital_Signs_Array = [0 if math.isnan(x) else x for x in Vital_Signs_Array]\n",
    "            Vital_Signs_Array = [Vital_Signs_Array]\n",
    "            print(Vital_Signs_Array)\n",
    "            json_data = {\"data\":{\"ndarray\":Vital_Signs_Array}}\n",
    "            response = requests.post(endpoint,json=json_data)\n",
    "            r=response.json()\n",
    "            SepsisLabel=int(r['data']['ndarray'][0])\n",
    "            print(\"Sepsis detected %s \" % int(r['data']['ndarray'][0]))\n",
    "            sql = \"INSERT INTO sepsis (PID ,Gender, Time,HR, Temp,Age,  O2Sat, SBP,Resp ,ICULOS,HospAdmTime,SepsisLabel,DetectedTime) VALUE ('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s' );\" % tuple([vitalsign_pid_filename,returnGender(Vital_Signs_Array[0][0]),k[0],Vital_Signs_Array[0][1],Vital_Signs_Array[0][2],Vital_Signs_Array[0][3],Vital_Signs_Array[0][4],Vital_Signs_Array[0][5],Vital_Signs_Array[0][6],Vital_Signs_Array[0][7],Vital_Signs_Array[0][8],SepsisLabel,current_timestamp])\n",
    "            cursor.execute(sql)\n",
    "            mydb.commit()\n",
    "            \n",
    "        with open(vitalsign_json_name, 'w') as outfile:\n",
    "            outfile.write(json.dumps(output, indent=4))\n",
    "        \n",
    "  \n",
    "        with open(labs_json_name, 'rb') as json_data:\n",
    "            output = json.load(json_data)\n",
    "\n",
    "        with open(labs_pid_filename + labscsv, 'r') as csv_labs:\n",
    "            r = csv.DictReader(csv_labs)\n",
    "            data_labs = [dict(d) for d in r]\n",
    "            \n",
    "        for k, g in groupby(data_labs, lambda r: (r['Time'], r['BaseExcess'],r['HCO3'],r['FiO2'],r['pH'],r['PaCO2'],r['SaO2'],r['AST'],r['BUN'],r['Alkalinephos'],r['Calcium'],r['Chloride'],r['Creatinine'],r['Bilirubin_direct'],r['Glucose'],r['Lactate'],r['Magnesium'],r['Phosphate'],r['Potassium'],r['Bilirubin_total'],r['TroponinI'],r['Hct'],r['Hgb'],r['PTT'],r['WBC'],r['Fibrinogen'],r['Platelets'])):\n",
    "            output['labs'].append({  \n",
    "                    \"Time\": k[0],\n",
    "                    \"BaseExcess\" :str(k[1]),\n",
    "                    \"HCO3\":str(k[2]),\n",
    "                    \"FiO2\": str(k[3]),\n",
    "                    \"pH\" :str(k[4]),\n",
    "                    \"PaCO2\":str(k[5]),\n",
    "                    \"SaO2\": str(k[6]),\n",
    "                    \"AST\" :str(k[7]),\n",
    "                    \"BUN\":str(k[8]),\n",
    "                    \"Alkalinephos\": str(k[9]),\n",
    "                    \"Calcium\" :str(k[10]),\n",
    "                    \"Chloride\":str(k[11]),\n",
    "                    \"Creatinine\": str(k[12]),\n",
    "                    \"Bilirubin_direct\" :str(k[13]),\n",
    "                    \"Glucose\":str(k[14]),\n",
    "                    \"Lactate\": str(k[15]),\n",
    "                    \"Magnesium\" :str(k[16]),\n",
    "                    \"Phosphate\":str(k[17]),\n",
    "                    \"Potassium\" :str(k[18]),\n",
    "                    \"Bilirubin_total\":str(k[19]),\n",
    "                    \"TroponinI\": str(k[20]),\n",
    "                    \"Hct\" :str(k[21]),\n",
    "                    \"Hgb\":str(k[22]),\n",
    "                    \"PTT\":str(k[23]),\n",
    "                    \"WBC\": str(k[24]),\n",
    "                    \"Fibrinogen\" :str(k[25]),\n",
    "                    \"Platelets\":str(k[26])\n",
    "            })\n",
    "        with open(labs_json_name, 'w') as outfile:\n",
    "            outfile.write(json.dumps(output, indent=4))\n",
    "        \n",
    "\n",
    "        f1 = open(vitalsign_pid_filename + vitalsignscsv)\n",
    "        csv_data_vitalsigns = csv.reader(f1)\n",
    "        f3 = open(vitalsign_pid_filename + vitalsignscsv)\n",
    "        csv_data_vitalsigns1 = csv.reader(f3)\n",
    "        lines=0\n",
    "        lines= len(list(csv_data_vitalsigns1))\n",
    "        f3.close()\n",
    "\n",
    "        f2 = open(labs_pid_filename + labscsv)\n",
    "        csv_data_labs = csv.reader(f2)\n",
    "        f4 = open(labs_pid_filename + labscsv)\n",
    "        csv_data_labs1 = csv.reader(f4)\n",
    "        f4.close()\n",
    "        header = next(csv_data_vitalsigns)\n",
    "        header = next(csv_data_labs)# This skips the first row of the CSV file. \n",
    "    \n",
    "\n",
    "        counter = 0\n",
    "        for (obj_vitalsigns, obj_labs) in itertools.zip_longest(csv_data_vitalsigns, csv_data_labs):\n",
    "\n",
    "            counter += 1\n",
    "            sql = \"INSERT INTO patient (PID  ,HR  ,O2Sat  ,Temp  ,SBP  ,MAP  ,DBP  ,Resp  ,EtCO2  ,BaseExcess  ,HCO3  ,FiO2  ,pH  ,PaCO2  ,SaO2  ,AST  ,BUN  ,Alkalinephos  ,Calcium  ,Chloride  ,Creatinine  ,Bilirubin_direct  ,Glucose  ,Lactate  ,Magnesium  ,Phosphate  ,Potassium  ,Bilirubin_total  ,TroponinI  ,Hct  ,Hgb  ,PTT  ,WBC  ,Fibrinogen  ,Platelets,Age,Gender,Unit1,Unit2,HospAdmTime,ICULOS ) VALUE (%(PID)s,%(HR)s,%(O2Sat)s,%(Temp)s,%(SBP)s,%(MAP)s,%(DBP)s,%(Resp)s,%(EtCO2)s,%(BaseExcess)s,%(HCO3)s,%(FiO2)s,%(pH)s,%(PaCO2)s,%(SaO2)s,%(AST)s,%(BUN)s,%(Alkalinephos)s,%(Calcium)s,%(Chloride)s,%(Creatinine)s,%(Bilirubin_direct)s,%(Glucose)s,%(Lactate)s,%(Magnesium)s,%(Phosphate)s,%(Potassium)s,%(Bilirubin_total)s,%(TroponinI)s,%(Hct)s,%(Hgb)s,%(PTT)s,%(WBC)s,%(Fibrinogen)s,%(Platelets)s,%(Age)s,%(Gender)s,%(Unit1)s,%(Unit2)s,%(HospAdmTime)s,%(ICULOS)s)\"\n",
    "            param_dict = {\"PID\": obj_vitalsigns[1], \"HR\": obj_vitalsigns[2],\"O2Sat\": obj_vitalsigns[3],\"Temp\": obj_vitalsigns[4],\"SBP\": obj_vitalsigns[5],\"MAP\": obj_vitalsigns[6],\"DBP\": obj_vitalsigns[7],\"Resp\": obj_vitalsigns[8],\"EtCO2\": obj_vitalsigns[9],\"BaseExcess\": obj_labs[2],\"HCO3\": obj_labs[3],\"FiO2\": obj_labs[4],\"pH\": obj_labs[5],\"PaCO2\": obj_labs[6],\"SaO2\": obj_labs[7],\"AST\": obj_labs[8],\"BUN\": obj_labs[9],\"Alkalinephos\": obj_labs[10],\"Calcium\": obj_labs[11],\"Chloride\": obj_labs[12],\"Creatinine\": obj_labs[13],\"Bilirubin_direct\": obj_labs[14],\"Glucose\": obj_labs[15],\"Lactate\": obj_labs[16],\"Magnesium\": obj_labs[17],\"Phosphate\": obj_labs[18],\"Potassium\": obj_labs[19],\"Bilirubin_total\": obj_labs[20],\"TroponinI\": obj_labs[21],\"Hct\": obj_labs[22],\"Hgb\": obj_labs[23] ,\"PTT\": obj_labs[24],\"WBC\": obj_labs[25],\"Fibrinogen\": obj_labs[26],\"Platelets\": obj_labs[27],\"Age\":calculateAge(Age), \"Gender\":returnSex(Gender),\"Unit1\":Unit1, \"Unit2\":Unit2,\"HospAdmTime\":HospAdmTime,\"ICULOS\":obj_vitalsigns[10]   }\n",
    "            cursor.execute(sql,param_dict)\n",
    "        f1.close()\n",
    "        f2.close()\n",
    "        mydb.commit()\n",
    "#        if counter > lines:\n",
    "#            break\n",
    "        json_name = vitalsign_json_name\n",
    "        client.fput_object(minio_creds['bucketName'], minio_prefix_json+json_name,json_name)\n",
    "    elif (diff < frequency):\n",
    "        with open(vitalsign_json_name, 'rb') as json_data:\n",
    "            output = json.load(json_data)\n",
    "        with open(vitalsign_pid_filename + vitalsignscsv, 'r') as csv_vital_signs:\n",
    "            r = csv.DictReader(csv_vital_signs)\n",
    "            data_vital_signs = [dict(d) for d in r]\n",
    "                \n",
    "        for k, g in groupby(data_vital_signs, lambda r: (r['Time'], r['HR'],r['O2Sat'],r['Temp'],r['SBP'],r['MAP'],r['DBP'],r['Resp'],r['EtCO2'],r['ICULOS'])):\n",
    "            output['Vital_Signs'].append({  \n",
    "                    \"Time\": k[0],\n",
    "                    \"HR\" :str(k[1]),\n",
    "                    \"O2Sat\" :str(k[2]),\n",
    "                    \"Temp\" :str(k[3]),\n",
    "                    \"SBP\" :str(k[4]),\n",
    "                    \"MAP\" :str(k[5]),\n",
    "                    \"DBP\" :str(k[6]),\n",
    "                    \"Resp\" :str(k[7]),\n",
    "                    \"EtCO2\":str(k[8]),\n",
    "                    \"ICULOS\":str(k[9])\n",
    "            })\n",
    "            Vital_Signs_Array = [returnSexInt(Gender),float(k[1]),float(k[3]),calculateAge(Age),float(k[2]),float(k[4]),float(k[7]),float(k[9]),float(HospAdmTime)]\n",
    "            Vital_Signs_Array = [0 if math.isnan(x) else x for x in Vital_Signs_Array]\n",
    "            Vital_Signs_Array = [Vital_Signs_Array]\n",
    "            print(Vital_Signs_Array)\n",
    "            json_data = {\"data\":{\"ndarray\":Vital_Signs_Array}}\n",
    "            response = requests.post(endpoint,json=json_data)\n",
    "            r=response.json()\n",
    "            SepsisLabel=int(r['data']['ndarray'][0])\n",
    "            print(\"Sepsis detected %s \" % int(r['data']['ndarray'][0]))\n",
    "            sql = \"INSERT INTO sepsis (PID ,Gender, Time,HR, Temp,Age,  O2Sat, SBP,Resp ,ICULOS,HospAdmTime,SepsisLabel,DetectedTime) VALUE ('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s' );\" % tuple([vitalsign_pid_filename,returnGender(Vital_Signs_Array[0][0]),k[0],Vital_Signs_Array[0][1],Vital_Signs_Array[0][2],Vital_Signs_Array[0][3],Vital_Signs_Array[0][4],Vital_Signs_Array[0][5],Vital_Signs_Array[0][6],Vital_Signs_Array[0][7],Vital_Signs_Array[0][8],SepsisLabel,current_timestamp])\n",
    "            cursor.execute(sql)\n",
    "            mydb.commit()\n",
    "            \n",
    "        with open(vitalsign_json_name, 'w') as outfile:\n",
    "            outfile.write(json.dumps(output, indent=4))\n",
    "        value = ''\n",
    "        fv = open(vitalsign_pid_filename + vitalsignscsv)\n",
    "        csv_data_vitalsigns = csv.reader(fv)\n",
    "        next(csv_data_vitalsigns)\n",
    "        for row in csv_data_vitalsigns:\n",
    "            sql = \"INSERT INTO patient (PID  ,HR  ,O2Sat  ,Temp  ,SBP  ,MAP  ,DBP  ,Resp  ,EtCO2,BaseExcess  ,HCO3  ,FiO2  ,pH  ,PaCO2  ,SaO2  ,AST  ,BUN  ,Alkalinephos  ,Calcium  ,Chloride  ,Creatinine  ,Bilirubin_direct  ,Glucose  ,Lactate  ,Magnesium  ,Phosphate  ,Potassium  ,Bilirubin_total  ,TroponinI  ,Hct  ,Hgb  ,PTT  ,WBC  ,Fibrinogen  ,Platelets,Age,Gender,Unit1,Unit2,HospAdmTime) VALUE ('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s' );\" % tuple([row[1], row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,value,calculateAge(Age),returnSex(Gender),Unit1,Unit2,HospAdmTime])\n",
    "            cursor.execute(sql)\n",
    "            mydb.commit()\n",
    "        fv.close()\n",
    "        json_name = vitalsign_json_name\n",
    "        client.fput_object(minio_creds['bucketName'], minio_prefix_json+json_name,json_name)\n",
    "\n",
    "    elif (diff1 < frequency):\n",
    "\n",
    "        with open(labs_json_name, 'rb') as json_data:\n",
    "            output = json.load(json_data)\n",
    "\n",
    "        with open(labs_pid_filename + labscsv, 'r') as csv_labs:\n",
    "            r = csv.DictReader(csv_labs)\n",
    "            data_labs = [dict(d) for d in r]\n",
    "            \n",
    "        for k, g in groupby(data_labs, lambda r: (r['Time'], r['BaseExcess'],r['HCO3'],r['FiO2'],r['pH'],r['PaCO2'],r['SaO2'],r['AST'],r['BUN'],r['Alkalinephos'],r['Calcium'],r['Chloride'],r['Creatinine'],r['Bilirubin_direct'],r['Glucose'],r['Lactate'],r['Magnesium'],r['Phosphate'],r['Potassium'],r['Bilirubin_total'],r['TroponinI'],r['Hct'],r['Hgb'],r['PTT'],r['WBC'],r['Fibrinogen'],r['Platelets'])):\n",
    "            output['labs'].append({  \n",
    "                    \"Time\": k[0],\n",
    "                    \"BaseExcess\" :str(k[1]),\n",
    "                    \"HCO3\":str(k[2]),\n",
    "                    \"FiO2\": str(k[3]),\n",
    "                    \"pH\" :str(k[4]),\n",
    "                    \"PaCO2\":str(k[5]),\n",
    "                    \"SaO2\": str(k[6]),\n",
    "                    \"AST\" :str(k[7]),\n",
    "                    \"BUN\":str(k[8]),\n",
    "                    \"Alkalinephos\": str(k[9]),\n",
    "                    \"Calcium\" :str(k[10]),\n",
    "                    \"Chloride\":str(k[11]),\n",
    "                    \"Creatinine\": str(k[12]),\n",
    "                    \"Bilirubin_direct\" :str(k[13]),\n",
    "                    \"Glucose\":str(k[14]),\n",
    "                    \"Lactate\": str(k[15]),\n",
    "                    \"Magnesium\" :str(k[16]),\n",
    "                    \"Phosphate\":str(k[17]),\n",
    "                    \"Potassium\" :str(k[18]),\n",
    "                    \"Bilirubin_total\":str(k[19]),\n",
    "                    \"TroponinI\": str(k[20]),\n",
    "                    \"Hct\" :str(k[21]),\n",
    "                    \"Hgb\":str(k[22]),\n",
    "                    \"PTT\":str(k[23]),\n",
    "                    \"WBC\": str(k[24]),\n",
    "                    \"Fibrinogen\" :str(k[25]),\n",
    "                    \"Platelets\":str(k[26])\n",
    "            })\n",
    "        with open(labs_json_name, 'w') as outfile:\n",
    "            outfile.write(json.dumps(output, indent=4))\n",
    "        value = ''\n",
    "        fl = open(labs_pid_filename + labscsv)\n",
    "        csv_data_labs = csv.reader(fl)\n",
    "        header = next(csv_data_labs)\n",
    "        for row in csv_data_labs:\n",
    "            sql = \"INSERT INTO patient (PID, HR  ,O2Sat  ,Temp  ,SBP  ,MAP  ,DBP  ,Resp  ,EtCO2, BaseExcess  ,HCO3  ,FiO2  ,pH  ,PaCO2  ,SaO2  ,AST  ,BUN  ,Alkalinephos  ,Calcium  ,Chloride  ,Creatinine  ,Bilirubin_direct  ,Glucose  ,Lactate  ,Magnesium  ,Phosphate  ,Potassium  ,Bilirubin_total  ,TroponinI  ,Hct  ,Hgb  ,PTT  ,WBC  ,Fibrinogen  ,Platelets,Age,Gender,Unit1,Unit2,HospAdmTime,ICULOS ) VALUE ('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s');\" % tuple([row[1],value,value,value,value,value,value,value,value, row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10],row[11],row[12],row[13],row[14],row[15],row[16],row[17],row[18],row[19],row[20],row[21],row[22],row[23],row[24],row[25],row[26],row[27],calculateAge(Age),returnSex(Gender),Unit1,Unit2,HospAdmTime,row[0]])\n",
    "            cursor.execute(sql)\n",
    "            mydb.commit()        \n",
    "        fl.close()\n",
    "        json_name = labs_json_name\n",
    "        client.fput_object(minio_creds['bucketName'], minio_prefix_json+json_name,json_name)\n",
    "\n",
    "files = glob.glob('p0*', recursive=True)\n",
    "for f in files:\n",
    "    try:\n",
    "        os.remove(f)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "print(\"Script Completed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
